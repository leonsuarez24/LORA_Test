{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USUARIO\\miniconda3\\envs\\leon_torch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.networks import DemoNet\n",
    "import peft\n",
    "import torch\n",
    "from utils import get_dataset_torch, AverageMeter\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:04<00:00, 5329890.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 155700.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:04<00:00, 933231.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel, im_size, num_classes, class_names, dst_train, dst_test, testloader, trainloader, valoader   = get_dataset_torch('FMNIST', 'data', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ACCURACY = MulticlassAccuracy(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, trainloader, valoader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        data_loop_train = tqdm(enumerate(trainloader), total=len(trainloader), colour='red')\n",
    "        train_accuracy = AverageMeter()\n",
    "        train_loss = AverageMeter()\n",
    "        for _, data in data_loop_train:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = ACCURACY(outputs, labels)\n",
    "\n",
    "            train_accuracy.update(accuracy.item(), inputs.size(0))\n",
    "            train_loss.update(loss.item(), inputs.size(0))\n",
    "            data_loop_train.set_description(f'Epoch {epoch+1}/{epochs}')\n",
    "            data_loop_train.set_postfix(loss=train_loss.avg, accuracy=train_accuracy.avg)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            data_loop_val = tqdm(enumerate(valoader), total=len(valoader), colour='green')\n",
    "            val_accuracy = AverageMeter()\n",
    "            val_loss = AverageMeter()\n",
    "            for _, data in data_loop_val:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                accuracy = ACCURACY(outputs, labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss.update(loss.item(), inputs.size(0))\n",
    "                val_accuracy.update(accuracy.item(), inputs.size(0))\n",
    "                data_loop_val.set_description(f'Epoch {epoch+1}/{epochs}')\n",
    "                data_loop_val.set_postfix(loss=val_loss.avg, accuracy=accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train without lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 100, 28, 28]           1,000\n",
      "            Conv2d-2          [-1, 100, 14, 14]          90,100\n",
      "            Conv2d-3              [-1, 1, 7, 7]             901\n",
      "            Linear-4                   [-1, 10]             500\n",
      "================================================================\n",
      "Total params: 92,501\n",
      "Trainable params: 92,501\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.75\n",
      "Params size (MB): 0.35\n",
      "Estimated Total Size (MB): 1.10\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DemoNet().to(device)\n",
    "print(summary(model, (1, 28, 28)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:09<00:00, 171.71it/s, accuracy=0.787, loss=0.555]\n",
      "Epoch 1/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:00<00:00, 221.13it/s, accuracy=0.75, loss=0.395] \n",
      "Epoch 2/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:17<00:00, 97.77it/s, accuracy=0.86, loss=0.367]  \n",
      "Epoch 2/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 165.91it/s, accuracy=0.889, loss=0.355]\n",
      "Epoch 3/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:11<00:00, 143.25it/s, accuracy=0.873, loss=0.324]\n",
      "Epoch 3/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:00<00:00, 207.11it/s, accuracy=0.952, loss=0.374]\n",
      "Epoch 4/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:11<00:00, 149.49it/s, accuracy=0.884, loss=0.299]\n",
      "Epoch 4/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:00<00:00, 218.35it/s, accuracy=0.833, loss=0.339]\n",
      "Epoch 5/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:27<00:00, 61.45it/s, accuracy=0.893, loss=0.279] \n",
      "Epoch 5/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:05<00:00, 35.38it/s, accuracy=1, loss=0.331]    \n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, trainloader, valoader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train with lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', models.networks.DemoNet),\n",
       " ('conv1', torch.nn.modules.conv.Conv2d),\n",
       " ('conv2', torch.nn.modules.conv.Conv2d),\n",
       " ('conv3', torch.nn.modules.conv.Conv2d),\n",
       " ('linear', torch.nn.modules.linear.Linear)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in DemoNet().named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(\n",
    "    r=1,\n",
    "    target_modules=[\"conv1\", \"linear\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 168 || all params: 92,669 || trainable%: 0.1813\n"
     ]
    }
   ],
   "source": [
    "model = DemoNet().to(device)\n",
    "model_copy = copy.deepcopy(model)\n",
    "\n",
    "peft_model = peft.get_peft_model(model, config)\n",
    "optimizer = torch.optim.Adam(peft_model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "peft_model.print_trainable_parameters() # previous wights + A, B matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 100, 28, 28]           1,000\n",
      "          Identity-2            [-1, 1, 28, 28]               0\n",
      "            Conv2d-3            [-1, 1, 28, 28]               9\n",
      "            Conv2d-4          [-1, 100, 28, 28]             100\n",
      "            Conv2d-5          [-1, 100, 28, 28]           1,000\n",
      "            Conv2d-6          [-1, 100, 14, 14]          90,100\n",
      "            Conv2d-7              [-1, 1, 7, 7]             901\n",
      "            Linear-8                   [-1, 10]             500\n",
      "          Identity-9                   [-1, 49]               0\n",
      "           Linear-10                    [-1, 1]              49\n",
      "           Linear-11                   [-1, 10]              10\n",
      "           Linear-12                   [-1, 10]             500\n",
      "          DemoNet-13                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 94,169\n",
      "Trainable params: 168\n",
      "Non-trainable params: 94,001\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.96\n",
      "Params size (MB): 0.36\n",
      "Estimated Total Size (MB): 2.32\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 100, 28, 28]           1,000\n",
      "            Conv2d-2          [-1, 100, 14, 14]          90,100\n",
      "            Conv2d-3              [-1, 1, 7, 7]             901\n",
      "            Linear-4                   [-1, 10]             500\n",
      "================================================================\n",
      "Total params: 92,501\n",
      "Trainable params: 92,501\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.75\n",
      "Params size (MB): 0.35\n",
      "Estimated Total Size (MB): 1.10\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(peft_model, (1, 28, 28)))\n",
    "print(summary(model_copy, (1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [01:03<00:00, 26.66it/s, accuracy=0.294, loss=1.58]\n",
      "Epoch 1/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:05<00:00, 33.35it/s, accuracy=0.167, loss=1.47]\n",
      "Epoch 2/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [01:02<00:00, 26.84it/s, accuracy=0.383, loss=1.44]\n",
      "Epoch 2/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:05<00:00, 35.66it/s, accuracy=0.556, loss=1.38]\n",
      "Epoch 3/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [01:04<00:00, 26.27it/s, accuracy=0.44, loss=1.37] \n",
      "Epoch 3/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:05<00:00, 33.72it/s, accuracy=0.407, loss=1.33]\n",
      "Epoch 4/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [01:02<00:00, 27.04it/s, accuracy=0.466, loss=1.32]\n",
      "Epoch 4/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:05<00:00, 32.03it/s, accuracy=0.407, loss=1.3] \n",
      "Epoch 5/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [01:00<00:00, 27.76it/s, accuracy=0.481, loss=1.29]\n",
      "Epoch 5/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:05<00:00, 35.25it/s, accuracy=0.378, loss=1.29]\n"
     ]
    }
   ],
   "source": [
    "train(peft_model, optimizer, criterion, trainloader, valoader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New parameter model.conv1.lora_A.default.weight |     9 parameters | updated\n",
      "New parameter model.conv1.lora_B.default.weight |   100 parameters | updated\n",
      "New parameter model.linear.lora_A.default.weight |    49 parameters | updated\n",
      "New parameter model.linear.lora_B.default.weight |    10 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"New parameter {name:<30} | {param.numel():>5} parameters | updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter model.conv1.base_layer.weight  |   900 parameters | not updated\n",
      "Parameter model.conv1.base_layer.bias    |   100 parameters | not updated\n",
      "Parameter model.conv2.weight             | 90000 parameters | not updated\n",
      "Parameter model.conv2.bias               |   100 parameters | not updated\n",
      "Parameter model.conv3.weight             |   900 parameters | not updated\n",
      "Parameter model.conv3.bias               |     1 parameters | not updated\n",
      "Parameter model.linear.base_layer.weight |   490 parameters | not updated\n",
      "Parameter model.linear.base_layer.bias   |    10 parameters | not updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"Parameter {name:<30} | {param.numel():>5} parameters | not updated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
